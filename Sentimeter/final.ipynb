{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8874743421204364\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "#import dataset\n",
    "csv_file_path = \"C:\\\\Users\\\\SATWIK M BADIGER\\\\Desktop\\\\projects\\\\ML\\\\Sentimeter\\\\dataset.csv\"\n",
    "df = pd.read_csv(csv_file_path)\n",
    "\n",
    "# Data Preprocessing\n",
    "df = df[df['Language'] == 'en']\n",
    "df.drop_duplicates(inplace=True)\n",
    "df['Text'] = df['Text'].apply(lambda x: re.sub(r'[^a-zA-Z\\s]', '', x))\n",
    "df['Text'] = df['Text'].apply(word_tokenize)\n",
    "\n",
    "# Vectorization\n",
    "vectorizer = CountVectorizer()\n",
    "X_bow = vectorizer.fit_transform([' '.join(tokens) for tokens in df['Text']])\n",
    "\n",
    "def vector():\n",
    "    return vectorizer\n",
    "\n",
    "#test and train data splitting\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_bow, df['Label'], test_size=0.2, random_state=42)\n",
    "\n",
    "#training Naive Bayes classifier\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "#making predictions\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "#model accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   litigious       0.90      0.89      0.89     35713\n",
      "    negative       0.84      0.92      0.88     48654\n",
      "    positive       0.91      0.87      0.89     49389\n",
      " uncertainty       0.92      0.87      0.90     39680\n",
      "\n",
      "    accuracy                           0.89    173436\n",
      "   macro avg       0.89      0.89      0.89    173436\n",
      "weighted avg       0.89      0.89      0.89    173436\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "#print classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Save the trained model to a file\n",
    "with open('naive_bayes_model.pkl', 'wb') as model:\n",
    "    pickle.dump(clf, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             Comment\n",
      "0  Your words become things. Manifest wisely:<br>...\n",
      "1                Oprah and the money preacher?? Nope\n",
      "2  Really need help with my mind set it really ke...\n",
      "3  Who is the last person that appears on the video?\n",
      "4                                     Get lost Harpo\n",
      "5                                  Clear mind spaceüôè\n",
      "6                                          Lol oprah\n",
      "7                  Thank you so much for this üôåüèæüôåüèæüôåüèæ\n",
      "8                      Minestroney Soup Acne Face. ü§Æ\n",
      "9          i want to sleep forever and never wake up\n"
     ]
    }
   ],
   "source": [
    "import googleapiclient.discovery\n",
    "import pandas as pd\n",
    "\n",
    "videoid = input(\"Enter the video id: \")\n",
    "\n",
    "api_service_name = \"youtube\"\n",
    "api_version = \"v3\"\n",
    "DEVELOPER_KEY = \"AIzaSyD1lXAVHpBQbDXaao5C-kTrBBkDbn1tvEI\"\n",
    "\n",
    "youtube = googleapiclient.discovery.build(\n",
    "    api_service_name, api_version, developerKey=DEVELOPER_KEY)\n",
    "\n",
    "request = youtube.commentThreads().list(\n",
    "    part=\"snippet\",\n",
    "    videoId=videoid,\n",
    "    maxResults=10\n",
    ")\n",
    "\n",
    "response = request.execute()\n",
    "\n",
    "comments = []\n",
    "\n",
    "for item in response['items']:\n",
    "    comment_text = item['snippet']['topLevelComment']['snippet']['textDisplay']\n",
    "    comments.append(comment_text)\n",
    "\n",
    "df = pd.DataFrame(comments, columns=['Comment'])\n",
    "\n",
    "print(df)\n",
    "\n",
    "def get_comments():\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8874743421204364\n",
      "                                             Comment\n",
      "0  Your words become things. Manifest wisely:<br>...\n",
      "1                Oprah and the money preacher?? Nope\n",
      "2  Really need help with my mind set it really ke...\n",
      "3  Who is the last person that appears on the video?\n",
      "4                                     Get lost Harpo\n",
      "5                                  Clear mind spaceüôè\n",
      "6                                          Lol oprah\n",
      "7                  Thank you so much for this üôåüèæüôåüèæüôåüèæ\n",
      "8                      Minestroney Soup Acne Face. ü§Æ\n",
      "9          i want to sleep forever and never wake up\n",
      "Positive\n",
      "\n",
      " 6 3 0 0 0\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "from model import vectorizer, vector, clf\n",
    "from webscrapping import get_comments\n",
    "df = get_comments()\n",
    "\n",
    "def preprocess_comment(comment):\n",
    "    # Lowercase each comment and remove non-alphabetic characters\n",
    "    comment = re.sub(r'[^a-zA-Z\\s]', '', comment).lower()\n",
    "    return comment\n",
    "\n",
    "# Apply preprocessing to all comments in the DataFrame\n",
    "df['Preprocessed_Comment'] = df['Comment'].apply(preprocess_comment)\n",
    "\n",
    "# Tokenization function\n",
    "def tokenize_comment(comment):\n",
    "    return word_tokenize(comment)\n",
    "\n",
    "# Tokenize the preprocessed comments\n",
    "df['Tokens'] = df['Preprocessed_Comment'].apply(tokenize_comment)\n",
    "\n",
    "# Vectorization function (using the same vectorizer as used during training)\n",
    "# Assuming you have 'vectorizer' available, if not, you need to load it from a file as well\n",
    "X_comments_bow = vectorizer.transform([' '.join(tokens) for tokens in df['Tokens']])\n",
    "\n",
    "# Predict sentiment for each comment\n",
    "df['Sentiment'] = clf.predict(X_comments_bow)\n",
    "\n",
    "# Count the occurrences of each sentiment label\n",
    "sentiment_counts = df['Sentiment'].value_counts()\n",
    "\n",
    "# Get counts for each sentiment label, defaulting to 0 if not found\n",
    "positive_count = sentiment_counts.get('positive', 0)\n",
    "negative_count = sentiment_counts.get('negative', 0)\n",
    "uncertain_count = sentiment_counts.get('uncertainy', 0)\n",
    "litigious_count = sentiment_counts.get('litigious', 0)\n",
    "if(positive_count == negative_count):\n",
    "    neutral_count = positive_count\n",
    "else:\n",
    "    neutral_count = 0\n",
    "\n",
    "# Check the counts to determine the overall sentiment\n",
    "if positive_count > negative_count and positive_count > uncertain_count and positive_count > litigious_count:\n",
    "    print(\"Positive\")\n",
    "elif negative_count > positive_count and negative_count > uncertain_count and negative_count > litigious_count:\n",
    "    print(\"Negative\")\n",
    "elif uncertain_count > positive_count and uncertain_count > negative_count and uncertain_count > litigious_count:\n",
    "    print(\"Uncertain\")\n",
    "elif litigious_count > positive_count and litigious_count > negative_count and litigious_count > uncertain_count:\n",
    "    print(\"Litigious\")\n",
    "elif positive_count == negative_count:\n",
    "    print(\"Neutral\")\n",
    "else:\n",
    "    print(\"Uncertain\")\n",
    "\n",
    "print(\"\\n\",positive_count, negative_count, uncertain_count, litigious_count, neutral_count)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
